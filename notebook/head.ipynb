{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/zf_projects/Lorsa/src')\n",
    "\n",
    "import torch\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.HookedTransformerConfig import HookedTransformerConfig\n",
    "from transformer_lens.components import Attention\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from models.lorsa import LowRankSparseAttention\n",
    "from config import LorsaTrainConfig, LorsaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorsa = LowRankSparseAttention.from_pretrained(\n",
    "    '/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/zf_projects/Lorsa/result/pythia-160m-lorsa-L5A',\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eef162d1a1042eebaff5867db93662a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = GPTNeoXForCausalLM.from_pretrained('/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/models/pythia-160m')\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained('/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/models/pythia-160m')\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    'EleutherAI/pythia-160m', \n",
    "    hf_model=hf_model, \n",
    "    tokenizer=tokenizer, \n",
    "    device='cuda',\n",
    "    hf_config=hf_model.config\n",
    ")\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# get original attention block\n",
    "orig_attn = model.blocks[lorsa.cfg.layer].attn\n",
    "\n",
    "# load dataset\n",
    "dataset_path = '/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/data/SlimPajama-3B'\n",
    "dataset = load_from_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdbc58537e94728835000ba6912a8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515dd340afcc4092bf8bfd30cbac0dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elt': tensor([[ 9.2140,  9.0521,  8.5536,  ...,  7.2810,  7.2633,  7.2200],\n",
      "        [10.3189, 10.2590, 10.0027,  ...,  8.8949,  8.8847,  8.8749],\n",
      "        [17.6253, 17.4367, 17.2300,  ..., 15.5040, 15.4961, 15.4922],\n",
      "        ...,\n",
      "        [29.0293, 25.0514, 23.5866,  ..., 17.1216, 17.1016, 17.0721],\n",
      "        [14.7810, 14.7504, 14.7476,  ..., 11.9625, 11.8930, 11.8667],\n",
      "        [27.7498, 27.7353, 27.7239,  ..., 25.5348, 25.5112, 25.4889]],\n",
      "       device='cuda:0'), 'context_idx': tensor([[246132, 187948, 149742,  ..., 357431, 338937, 255002],\n",
      "        [176031,  44468, 239690,  ..., 181643, 153645,  33107],\n",
      "        [ 17379, 317247,  31091,  ...,  11164,  28462, 133725],\n",
      "        ...,\n",
      "        [208799, 352219,  55843,  ..., 189515, 153426, 248468],\n",
      "        [243482, 339795, 110198,  ..., 292465,  86638, 199283],\n",
      "        [118015, 128137,  56246,  ...,  43318, 374343, 210155]],\n",
      "       device='cuda:0', dtype=torch.int32), 'dfa_of_max_activating_samples': tensor([[[ 6.3942e-03, -1.6435e-03, -1.6765e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.1508e-03,  8.7292e-06, -1.9546e-06,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 7.8588e-04,  2.5125e-06, -5.2511e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.6659e-02,  5.6676e-06, -3.4940e-05,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 9.5743e-03, -1.5338e-04,  1.0182e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2649e-02,  1.1722e-05,  1.0712e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.4310e-02, -6.1768e-06,  1.4721e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2369e-02,  1.7461e-03,  6.3033e-06,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 1.3934e-03, -3.9286e-06,  7.9612e-06,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 3.6819e-03, -1.5510e-03,  3.2415e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 7.2512e-03, -5.7569e-06,  8.5279e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.6930e-03,  3.8264e-05,  6.3671e-07,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[ 1.7906e-03, -1.5293e-05,  1.1645e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.6746e-03,  3.8098e-03,  4.4146e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4074e-03, -7.1001e-06,  3.0022e-07,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.8002e-03, -7.8248e-05,  1.0310e-03,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.9940e-03, -4.6699e-05, -4.0898e-04,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1025e-04, -1.0151e-04,  7.4121e-05,  ...,  3.5349e-02,\n",
      "           1.5077e-01,  6.8616e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0813e-01,  3.4295e-05, -8.6054e-06,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2411e-01, -7.8594e-06,  4.5576e-04,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 8.9750e-02,  1.2428e-05,  4.7246e-02,  ..., -8.5781e-04,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.4446e-01,  5.7715e-04,  3.3022e-03,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 4.3833e-04,  6.1724e-04,  5.0434e-04,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4254e-02,  7.1214e-04, -1.6878e-05,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[ 2.6190e-03,  1.9562e-05,  9.1274e-06,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 2.0970e-05,  1.6922e-06,  2.8705e-06,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4313e-07,  3.7163e-08,  8.3166e-09,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.4223e-02,  1.8340e-05, -4.0161e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 6.1300e-03, -5.8261e-05,  9.5765e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 3.5332e-03,  1.1860e-04, -1.8933e-05,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.3127e-03, -1.8141e-05, -4.2988e-05,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 1.5023e-04, -1.6886e-06,  2.4319e-05,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 1.6813e-04,  6.1938e-06,  4.6066e-06,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.0548e-03, -9.0257e-06, -8.7415e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.4752e-03, -6.4268e-04,  4.7923e-04,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 3.9107e-04,  1.9588e-07,  1.2444e-05,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0'), 'q_pos_of_max_activating_samples': tensor([[113,  38, 150,  ..., 132, 151, 165],\n",
      "        [125, 120,  85,  ...,  81,  92, 183],\n",
      "        [240, 105, 100,  ..., 151, 190, 255],\n",
      "        ...,\n",
      "        [ 85, 189, 253,  ..., 204, 188, 149],\n",
      "        [104, 198, 226,  ..., 117, 103,  58],\n",
      "        [175, 230, 234,  ..., 225,  87, 242]], device='cuda:0'), 'act_times': tensor([ 2681485,  1799437,  5973341,  9894472,   840258,   294404,   772126,\n",
      "         1297619,  4480080,  1423667,   473247,  1157849,  2357813,  1724936,\n",
      "          602918,   512000,   168424,   131535,    52734,   123991,    28424,\n",
      "          502627,   196756,    77967,   158460,    17164,   115988,    95048,\n",
      "          228765,   284533,   104578,    89716,    15986,    57827,    69961,\n",
      "          100451,    33907,    42629,    11874,   118111, 80495334,    14899,\n",
      "           45918,     9319,    12164,    75614,    12997,    19038,   143031,\n",
      "          174186,   284276,    61732,   322499,   298079,    74960,   552540,\n",
      "          140886,   323007,   144756,   373183,   365666,  2046015,    54695,\n",
      "          526910,  7456047,  7998595,  1611863, 21105402,   962894,  3224850,\n",
      "         8226826,  4843033,  3251417, 16157429,  3803474,  7207298,  7591624,\n",
      "        14099958,  2136972, 10638434,        0,        0,        0,        0,\n",
      "               0,        0,        0,        0,        0,        0,        0,\n",
      "               0,        0, 76178036,        0,        0,  2253483,  6740241,\n",
      "         1345941,  2014122,  4151592,  4245035,  1193150,  1274734,  3433618,\n",
      "         3434982,  3428586,  1684182, 11750670,  1687174,   693863,  1921422,\n",
      "          205482,    29582,    10491,    24841,  1467424, 35760837,   118210,\n",
      "           87769,    26172,    61518,   191905, 21461842, 41900197,    58207,\n",
      "        57304386,   174017,  2479601,  1690015,  2768602,  1960549,  2563515,\n",
      "         7437171,  6413803,  4713686,  6125332,  3879599,   631930,  1156169,\n",
      "         7613640,  9086517,  5126984,  2410869,        0,        0,        0,\n",
      "               0,        0,        0,  3824677,        0,        0, 84887112,\n",
      "               0,        0,        0,        0,        0,        0,  1435924,\n",
      "         4201006, 29828761,   300756,  3037769,   797274,  2290480,  1256405,\n",
      "         2255797,  1344464,  8736797,   774829,  1021227,  3619390,   708256,\n",
      "         8534151,  2390828,   437816,   350526,   674419,   542975,   321484,\n",
      "          381683,   224133,   265513,  1129497,   351485,   345324,   291837,\n",
      "          589787,   560577,   244144,   422842,  1783579,  2204671,   129905,\n",
      "          479948,   986376,   734955,   424120,   149228,   161781,   451854,\n",
      "         1101032,   510373,   156440,    73437,   631261,  1053506,  1207520,\n",
      "         2181500,   951210,  1327519,  5518128,   509388,  1135784,  5776594,\n",
      "         2477171,  1215046,  1872871,  2160637,   250104,  3733069,  2000308,\n",
      "         2548744,  2081618,  2371950,  1118767,  2589220,  2299116,  2204071,\n",
      "         2071815,  1186776,  1111347,   919142,  1013803,  2609661,  2044311,\n",
      "         1201075,  2303034,     1086,     3305,     5198,    13451,     4654,\n",
      "            2231,     2277,      147,     2371,       83,     4116,     1011,\n",
      "            2168,     3249,      787,      188,  3396856,   698674,   557719,\n",
      "         1084938,   704958,  1025602,   987018, 82697838,  1117021,  1338760,\n",
      "         1452599,   984077,   549094,   695298,  1543531,   961756,      360,\n",
      "        21552464,      205,      278,      396, 83073087, 55396953,       14,\n",
      "             257, 72820965,       14,      479,      129,       76, 80076681,\n",
      "              22,  2117118,   617463,  1018094,   658158,  1463668,   624276,\n",
      "         1385443,   891391,  1008895,  1227959,  1363694,  4060904,   883479,\n",
      "         2078604,  1139864,  1855839,    95704,   588440,  1869401,    17951,\n",
      "           20619,   123258,   141069,   563218,   455256,   702080,     4852,\n",
      "           68329,   240082,    55073,     4536,   603714, 48685978,   776533,\n",
      "               0,        0,        0,        0,  1130913,        0,        0,\n",
      "               0, 17306470,      199,        0,        0,        0,        1,\n",
      "          168686,  2769633,    35130,    42477,   268752,   312262,    91381,\n",
      "           37787,    31361,    15760,    45758,    61771,   173259,   527727,\n",
      "           36731,  4013465,   249430,   280283, 68382771,  4889633,   849462,\n",
      "          242395,  2530587,   810679,   378595,  1800934,   162365,   869259,\n",
      "         1575905,   642055,   893414,  1358138,   326161,   718862,  1950188,\n",
      "         1296233,   839074,   419661,   594783,  2007978,   572265,   484321,\n",
      "           77052,  2010558,  1628463,  3268770,   371442,    87347,   122563,\n",
      "           78569,   159951,    22423, 20184748,   265621,   958925,   324407,\n",
      "         3542966,   231818,    60206,   803757,   200777,    64099, 36703301,\n",
      "          107677,   446829,   787856,  4132704,  2018848,  1243268,  6419772,\n",
      "         2726698,   230640,  1640678,   890320,   421576,  2822854,  1283994,\n",
      "         2651117,   914166,  1536938,   101341,   218864,   643825,  1013474,\n",
      "          589483,   866594,   228470,   415539,   399053,  2848037,   631511,\n",
      "          277586,  1672210,  1109849,    35657,   361717, 66430985,  1057640,\n",
      "         4532480,  4200783,  2429269,  1618733, 14633830,  3705224,  7087165,\n",
      "         1691626,  3426620,  6828648,  2786327,  3937155,  1625579,  2754674,\n",
      "           46588,   319847,   527783,   383865,   176211,   108845,   820880,\n",
      "          907138,   479273,  1062789,   302257,   330185,   234426,   548650,\n",
      "           96733,    93170,   276210,   248063,   338895,   206394,   274705,\n",
      "          352705,   320167,   403877,   281269,   278727,   248079,   477275,\n",
      "          655246,   632914,   260887,   357129,   125843,   220185,  2880761,\n",
      "            7158,    92130,    71583,    48203,    16461,   134398,    75022,\n",
      "         1002881,    77776,   310902,    22400,     1874,  1233476,   191830,\n",
      "           24740,    14091,    40747,   121514,   997872,    24978, 37190154,\n",
      "        75470493,   424857,    15271, 37785902, 84768226,    28339,   130002,\n",
      "           69155, 82603018,   637083,  1220763,  1795345,  1486080,  1413136,\n",
      "         1869540,   922639,   589436,   270641,  1088637,  1058152,   647957,\n",
      "          390348,   391587,   457608,  1304044,  2733562,  2626844,   528274,\n",
      "         2028313,  1173570,  2780022,  1066590,  3663735,  2251674,  5149236,\n",
      "         3429862,  1574897,  3054192,   760167,  1664707,   830469,   647620,\n",
      "            2735,   322715,    55078,   151507,   205883,   352957,   853566,\n",
      "          461909,   226693,   721445,   218599,   224521,   560775,   756902,\n",
      "               1, 10335423,       10,        1, 45925275, 28474694,        6,\n",
      "               0,        0,        9,        2,        2,        0,        0,\n",
      "               3,        0,    98402,    77200,    82091,   159335,   156420,\n",
      "           36664,    68863,   266466,    49948,    36465,    44818,    19103,\n",
      "          135285,    85553,    27109,   208749,  6263033,  3159708,  4075502,\n",
      "         2660986,   294311,  3546337,  2005857,   566792,  2141643,   296752,\n",
      "         1991974,   709918,  1066194,   536293,   672939,  1089919,  1198625,\n",
      "          780240,  2545564,   257324,   878021,   894226,   612213,  2117625,\n",
      "         1840406,   369749,  6909149,  2923394,   929855,   739715,   923808,\n",
      "         1024697,  1457610,  2118969,  2938151,   498138,  4090811,  1510205,\n",
      "         5571902,  3563552,  3798773,  9965784,  8780633,  5729829,   947724,\n",
      "         2821280,  1941315,  2703344,    30481,   863351,   587504,   228064,\n",
      "          493974,  1813006,   399756,    43660,   161117,   233461,    71108,\n",
      "           33395,    79001,    95649,   463751,    76031,  2192752,  1862028,\n",
      "         2333083,  2645163,  1790181,  2750919,  1547672,  1473624,  1269166,\n",
      "         1184669,  4434286,  1223230,  1445922,  1422627,  3207273,  1484768,\n",
      "        56950490,   487947,   340876,    79208,   318833,    56632,    26985,\n",
      "          294913,   413593,   785682,    75612,   197984,    95744,    86801,\n",
      "          309186,   108544,   335707,  1254058,    29148,   967955,  3923195,\n",
      "          973913,   517429,   117254,   218183,   125816,  1613192,   218805,\n",
      "          178627,   341089,   146675,   655933,   305725,   275432,   584668,\n",
      "        17195484,  8359993,    82258,  2060163,    71105,   258209,   136521,\n",
      "           77776,   488668,   530828,   914822,   167437,   810291,     5581,\n",
      "           49106,    46213, 87762598,    27863,    69507,    91466, 64398185,\n",
      "            9399,   984657,    60245,    82300,   330194,    31923,    50298,\n",
      "           44970,   514412,   607216,   308103,   514366,   289299,   469434,\n",
      "          416089,   709857,   433948,   630155,  1515450,   162395,   244701,\n",
      "          419575,   306829,   121275,   234304,  1355093,    42827,   430720,\n",
      "          115791,  1427253,  1537495,   322442,  1259712,   125171,  1884753,\n",
      "           18329,   197830, 81438728,   769491,   397620], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "total_analyzing_tokens=100000000\n",
    "from analysis.top_activating_dfa import sample_max_activating_sequences\n",
    "\n",
    "ignore_tokens = {\n",
    "    model.tokenizer.bos_token_id,\n",
    "    model.tokenizer.eos_token_id,\n",
    "    model.tokenizer.pad_token_id,\n",
    "}\n",
    "\n",
    "lorsa.fold_W_O_into_W_V()\n",
    "\n",
    "sample_results = sample_max_activating_sequences(\n",
    "    lorsa=lorsa, \n",
    "    dataset=dataset.select(range(total_analyzing_tokens // lorsa.cfg.n_ctx)), \n",
    "    model=model,\n",
    "    ignore_tokens=ignore_tokens,\n",
    "    batch_size=32,\n",
    "    get_topn_activating_samples=32,\n",
    ")\n",
    "\n",
    "print(sample_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of setuptools._distutils failed: Traceback (most recent call last):\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/importlib/__init__.py\", line 128, in reload\n",
      "    spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1262, in _find_spec\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/_distutils_hack/__init__.py\", line 109, in find_spec\n",
      "    return method()\n",
      "           ^^^^^^^^\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/_distutils_hack/__init__.py\", line 141, in spec_for_distutils\n",
      "    'distutils', DistutilsLoader(), origin=mod.__file__\n",
      "                                           ^^^^^^^^^^^^\n",
      "AttributeError: module 'distutils' has no attribute '__file__'. Did you mean: '__name__'?\n",
      "]\n",
      "[autoreload of more_itertools failed: Traceback (most recent call last):\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/importlib/__init__.py\", line 130, in reload\n",
      "    raise ModuleNotFoundError(f\"spec not found for the module {name!r}\", name=name)\n",
      "ModuleNotFoundError: spec not found for the module 'more_itertools'\n",
      "]\n",
      "/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "[autoreload of setuptools failed: Traceback (most recent call last):\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/setuptools/__init__.py\", line 288, in <module>\n",
      "    monkey.patch_all()\n",
      "  File \"/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/miniconda3/envs/zflorsa/lib/python3.12/site-packages/setuptools/monkey.py\", line 82, in patch_all\n",
      "    module.Distribution = setuptools.dist.Distribution\n",
      "                          ^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'setuptools' has no attribute 'dist'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "torch.save(sample_results, '/inspire/hdd/ws-8207e9e2-e733-4eec-a475-cfa1c36480ba/embodied-multimodality/public/zfhe/zf_projects/Lorsa/result/pythia-160m-lorsa-L5A/sample_results.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
